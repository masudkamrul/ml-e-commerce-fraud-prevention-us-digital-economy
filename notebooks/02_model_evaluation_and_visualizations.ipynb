# ============================
# Load Dependencies
# ============================
import pandas as pd
import requests
import gzip
import joblib
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc

# ============================
# Load compressed model from GitHub
# ============================
model_url = "https://github.com/masudkamrul/ml-e-commerce-fraud-prevention-us-digital-economy/raw/main/models/advanced_fraud_model_compressed.joblib.gz"
model_filename = "advanced_fraud_model_compressed.joblib.gz"

# Download model file
r = requests.get(model_url)
open(model_filename, "wb").write(r.content)

# Load model pipeline
with gzip.open(model_filename, "rb") as f:
    pipeline = joblib.load(f)

print("✔ Model loaded successfully")

# ============================
# Load Dataset from GitHub
# ============================
data_url = "https://raw.githubusercontent.com/masudkamrul/ml-e-commerce-fraud-prevention-us-digital-economy/main/data/Fraudulent_E_Commerce_Transactions.csv"
df = pd.read_csv(data_url)

# =====================================
# Prepare Data
# =====================================
target = "Is Fraudulent"
X = df.drop(columns=[target])
y = df[target]

# Predictions
y_pred = pipeline.predict(X)
y_proba = pipeline.predict_proba(X)[:, 1]

acc = accuracy_score(y, y_pred)
acc_text = f"Accuracy: {acc:.2f}"
print(acc_text)

# =====================================
# Confusion Matrix
# =====================================
cm = confusion_matrix(y, y_pred)
disp = ConfusionMatrixDisplay(cm, display_labels=["Legit", "Fraud"])
disp.plot(cmap="Blues", values_format="d")
plt.title(f"Confusion Matrix — Advanced Model ({acc_text})")
plt.show()

# =====================================
# ROC Curve
# =====================================
fpr, tpr, _ = roc_curve(y, y_proba)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.3f}")
plt.plot([0, 1], [0, 1], "--")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title(f"ROC Curve — Advanced Model ({acc_text})")
plt.legend()
plt.grid(True)
plt.show()

print(f"\nROC AUC Score: {roc_auc:.3f}")

# =====================================
# Top Fraud Indicators
# =====================================
model = pipeline.named_steps["model"]
feature_names = pipeline.named_steps["preprocess"].get_feature_names_out()
importances = model.feature_importances_

# Group back to original categories
grouped = {}
for name, imp in zip(feature_names, importances):
    key = name.split("__")[-1].split("_")[0]
    grouped[key] = grouped.get(key, 0) + imp

top = sorted(grouped.items(), key=lambda x: x[1], reverse=True)[:8]
names, values = zip(*top)

plt.figure(figsize=(8,5))
plt.barh(names, values)
plt.title(f"Top Indicators — Advanced Model ({acc_text})")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

print("✔ Visual evaluation complete")
